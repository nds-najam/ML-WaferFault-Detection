{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Get the preprocessed data input file\n",
    "2) Consider algorithms for model training\n",
    "3) Split the data into training and test data\n",
    "4) Hyperparameter tuning of algorithms for best models for all the clusters\n",
    "5) Select the best models for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "os.chdir(Path(\"E:\\FSDS_NOV\\ML-WaferFault-Detection\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from waferFaultDetection.constants import *\n",
    "from waferFaultDetection.utils import read_yaml,create_directories\n",
    "from waferFaultDetection import logger\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainingConfig:\n",
    "    '''\n",
    "    Define the resources required for the Model Training\n",
    "    such as dataset file name, label column name, null data summary, standard deviation summary etc.\n",
    "    '''\n",
    "    root_dir: Path\n",
    "    preprocessed_model_input_file: Path\n",
    "    cluster_label: str\n",
    "    label_column_name: str\n",
    "    models_directory: Path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from waferFaultDetection import logger\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH\n",
    "        ):\n",
    "\n",
    "        logger.info(\"reading yaml files for configs and parameters\")\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        logger.info(\"creating directory for artifacts\")\n",
    "        create_directories([self.config.artifacts_root])\n",
    "        logger.info(\"artifacts directory created\")\n",
    "\n",
    "    def get_model_training_config(self) -> ModelTrainingConfig:\n",
    "        config = self.config.model_training\n",
    "        logger.info(\"creating model training root directory\")\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        logger.info('creating model training configuration')\n",
    "        model_training_config = ModelTrainingConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            preprocessed_model_input_file = config.preprocessed_model_input_file,\n",
    "            cluster_label = config.cluster_label,\n",
    "            label_column_name = config.label_column_name,\n",
    "            models_directory = config.models_directory\n",
    "        )\n",
    "        return model_training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from waferFaultDetection import logger\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics  import roc_auc_score,accuracy_score\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"\n",
    "        This class shall  be used to train the model and finding the best model for each cluster.\n",
    "\n",
    "        Written By: Najam Sheikh\n",
    "        Version: 1.0\n",
    "        Revisions: None\n",
    "\n",
    "        \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config:ModelTrainingConfig\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.rfc = RandomForestClassifier()\n",
    "        self.xgb = XGBClassifier(objective='binary:logistic')\n",
    "\n",
    "    def get_best_params_for_RFC(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Method Name: get_best_params_for_RFC\n",
    "            Description: get the parameters for Random Forest Algorithm that gives the best accuracy.\n",
    "                            Use Hyper Parameter Tuning.\n",
    "            Output: The model with the best parameters\n",
    "            On Failure: Raise Exception\n",
    "\n",
    "            Written By: Najam\n",
    "            Version: 1.0\n",
    "            Revisions: None\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info(\"Entered the (get_best_params_for_RFC) module\")\n",
    "        try:\n",
    "            # initializing the grid parameters\n",
    "            logger.info('RFC:initializing the grid parameters')\n",
    "            param_grid = {'n_estimators':[10,50,100,130],'criterion':['gini','entropy'],\n",
    "                            'max_depth':range(2,4,1),'max_features':['sqrt','log2']}\n",
    "            \n",
    "            # Creating an object of the Grid Search Class and finding best parameters\n",
    "            grid = GridSearchCV(estimator=self.rfc,param_grid=param_grid,cv=5,verbose=3)\n",
    "            grid.fit(X_train,y_train)\n",
    "            logger.info('RFC: Grid search and Fit complete')\n",
    "\n",
    "            # Extracting best parameters\n",
    "            n_estimators = grid.best_params_['n_estimators']\n",
    "            criterion = grid.best_params_['criterion']\n",
    "            max_depth = grid.best_params_['max_depth']\n",
    "            max_features = grid.best_params_['max_features']\n",
    "            logger.info('RFC:Extracting best parameters complete')\n",
    "\n",
    "            # Creating a new model with the best parameters\n",
    "            self.rfc = RandomForestClassifier(n_estimators=n_estimators,criterion=criterion,\n",
    "                                                max_depth=max_depth,max_features=max_features)\n",
    "            logger.info('RFC: Creating a new model with the best parameters complete')\n",
    "            \n",
    "            # Train the new model\n",
    "            self.rfc.fit(X_train,y_train)\n",
    "            logger.info('RFC: Training the new model complete')\n",
    "\n",
    "            logger.info(f'Random Forest best parameters:{grid.best_params_}')\n",
    "            logger.info('Exited the (get_best_params_for_RFC) module')\n",
    "            return self.rfc\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Exception occured in (get_best_params_for_RFC) method. Exception message:{str(e)}\")\n",
    "            logger.info(\"Getting best parameters for Random Forest Classifier unsuccessful\")\n",
    "            raise e\n",
    "\n",
    "    def get_best_params_for_XGB(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Method Name: get_best_params_for_XGB\n",
    "            Description: get the parameters for XG Boost Algorithm that gives the best accuracy.\n",
    "                            Use Hyper Parameter Tuning.\n",
    "            Output: The model with the best parameters\n",
    "            On Failure: Raise Exception\n",
    "\n",
    "            Written By: Najam\n",
    "            Version: 1.0\n",
    "            Revisions: None\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info(\"Entered the (get_best_params_for_XGB) module\")\n",
    "        try:\n",
    "            # initializing the grid parameters\n",
    "            param_grid = {'learning_rate':[0.5, 0.1, 0.01, 0.001],\n",
    "                            'max_depth':range(2,4,1),\n",
    "                            'n_estimators': [10, 50, 100, 200]}\n",
    "            \n",
    "            # Creating an object of the Grid Search Class and finding best parameters\n",
    "            grid = GridSearchCV(estimator=self.xgb,param_grid=param_grid,cv=5,verbose=3)\n",
    "            grid.fit(X_train,y_train)\n",
    "            logger.info('XGB Grid fit complete')\n",
    "\n",
    "            # Extracting best parameters\n",
    "            n_estimators = grid.best_params_['n_estimators']\n",
    "            learning_rate = grid.best_params_['learning_rate']\n",
    "            max_depth = grid.best_params_['max_depth']\n",
    "            logger.info('XGB best parameters extraction complete')\n",
    "\n",
    "            # Creating a new model with the best parameters\n",
    "            logger.info('XGB Classifier: Creating a new model with the best parameters ')\n",
    "            self.xgb = XGBClassifier(learning_rate=learning_rate,\n",
    "                                    max_depth=max_depth,\n",
    "                                    n_estimators=n_estimators)\n",
    "\n",
    "            # Train the new model\n",
    "            logger.info('XGB: Train the new model started')\n",
    "            self.xgb.fit(X_train,y_train)\n",
    "            logger.info(f'XG Boost Classifier best parameters:{grid.best_params_}')\n",
    "            logger.info('Exited the (get_best_params_for_XGB) module')\n",
    "            return self.xgb\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Exception occured in (get_best_params_for_XGB) method. Exception message:{str(e)}\")\n",
    "            logger.info(\"Getting best parameters for XG Boost Classifier unsuccessful\")\n",
    "            raise e\n",
    "\n",
    "    def find_best_model(self,X_train,y_train,X_test,y_test):\n",
    "        \"\"\"\n",
    "            Method Name: find_best_model\n",
    "            Description: Find best model for each training and testing dataset with best AUC score\n",
    "            Output: The model with the best parameters\n",
    "            On Failure: Raise Exception\n",
    "\n",
    "            Written By: Najam\n",
    "            Version: 1.0\n",
    "            Revisions: None\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info('Entered (find_best_model) method')\n",
    "        try:\n",
    "            # Create the best model for XGBoost and make prediction\n",
    "            self.xgb = self.get_best_params_for_XGB(X_train,y_train)\n",
    "            pred_xgb = self.xgb.predict(X_test)\n",
    "            logger.info('XGB: Create the best model for XGBoost and make prediction')\n",
    "\n",
    "            # if there's only one label in y, roc_auc_score fails. Instead use accuracy_score\n",
    "            logger.info(\"if there's only one label in y, roc_auc_score fails. Instead use accuracy_score\")\n",
    "            if len(y_test.unique() == 1):\n",
    "                xgb_score = accuracy_score(y_test,pred_xgb)\n",
    "                logger.info(f'Accuracy score for XG Boost is {xgb_score}')\n",
    "            else:\n",
    "                xgb_score = roc_auc_score(y_test,pred_xgb) # AUC score\n",
    "                logger.info(f'AUC score for XG Boost is {xgb_score}')\n",
    "            logger.info('XGB: score calculation complete')\n",
    "\n",
    "            # Create the best model for Random Forest Classifier and make prediction\n",
    "            self.rfc = self.get_best_params_for_RFC(X_train,y_train)\n",
    "            pred_rfc = self.rfc.predict(X_test)\n",
    "            logger.info('RFC: Create the best model for Random Forest and make prediction')\n",
    "\n",
    "            # if there's only one label in y, roc_auc_score fails. Instead use accuracy_score\n",
    "            if len(y_test.unique() == 1):\n",
    "                rfc_score = accuracy_score(y_test,pred_rfc)\n",
    "                logger.info(f'Accuracy score for Random Forest Classifier is {rfc_score}')\n",
    "            else:\n",
    "                rfc_score = roc_auc_score(y_test,pred_rfc) # AUC score\n",
    "                logger.info(f'AUC score for Random Forest Classifier is {rfc_score}')\n",
    "            logger.info('RFC: score calculation complete')\n",
    "\n",
    "            # Comparison of two models\n",
    "            if(rfc_score < xgb_score):\n",
    "                return 'XGBoost',self.xgb\n",
    "            else:\n",
    "                return 'RandomForest',self.rfc\n",
    "            logger.info(f'XGBoost_Score:{xgb_score} \\t RandomForest_Score:{rfc_score}')\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Exception occured in (find_best_model) method. Exception message:{str(e)}\")\n",
    "            logger.info(\"Finding of best model unsuccessful\")\n",
    "            raise e\n",
    "\n",
    "    def train_model(self):\n",
    "        \"\"\"\n",
    "                Method Name: train_model\n",
    "                Description: This method trains individual cluster with best model and saves them.\n",
    "                Output: A pickle model file for each cluster.\n",
    "                On Failure: Raise Exception\n",
    "\n",
    "                Written By: Najam Sheikh\n",
    "                Version: 1.0\n",
    "                Revisions: None\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info('Entered (create_model_df) method')\n",
    "        try:\n",
    "            data = pd.read_csv(self.config.preprocessed_model_input_file)\n",
    "            list_of_clusters = data[self.config.cluster_label].unique()\n",
    "            \n",
    "            # replace the Good/bad labels to 0 and 1 from -1 and 1\n",
    "            data[self.config.label_column_name].replace(to_replace={-1:0},inplace=True)\n",
    "            logger.info('Replaced -1 with 0 for logistic regression')\n",
    "            \n",
    "            for cluster in list_of_clusters:\n",
    "                # Create features matrix\n",
    "                X = data[data[self.config.cluster_label] == cluster]\n",
    "                X = X.drop(labels=[self.config.cluster_label,self.config.label_column_name],axis=1)\n",
    "                logger.info('Created X features matrix')\n",
    "\n",
    "                # Create labels vector\n",
    "                y = data[data[self.config.cluster_label] == cluster]\n",
    "                y = y[self.config.label_column_name]\n",
    "                logger.info('Created y labels vector')\n",
    "\n",
    "                # Split training and testing datasets\n",
    "                X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=355)\n",
    "                logger.info('Splitted X and y as training and testing datasets')\n",
    "\n",
    "                # Find best model for the cluster\n",
    "                best_model_name,best_model = self.find_best_model(X_train,y_train,X_test,y_test)\n",
    "\n",
    "                # Saving best model to the directory\n",
    "                if not os.path.exists(self.config.models_directory):\n",
    "                    os.makedirs(self.config.models_directory)\n",
    "                file = best_model_name + f'_cluster_{cluster}.sav'\n",
    "                filepath = os.path.join(self.config.models_directory,file)\n",
    "                with open(filepath,'wb') as f:\n",
    "                    pickle.dump(best_model,f)\n",
    "\n",
    "                logger.info(f'Saved best model:{best_model_name} for cluster:{cluster}')\n",
    "                logger.info('Exited (train_model) method')\n",
    "        except Exception as e:\n",
    "            logger.info(f\"Exception occured in (create_model_df) method. Exception message:{str(e)}\")\n",
    "            logger.info(\"Training of model unsuccessful\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-11 12:38:24,043: INFO: 4239026115]: reading yaml files for configs and parameters\n",
      "[2023-02-11 12:38:24,053: INFO: common]: yaml file: configs\\config.yaml loaded successfully\n",
      "[2023-02-11 12:38:24,057: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2023-02-11 12:38:24,059: INFO: 4239026115]: creating directory for artifacts\n",
      "[2023-02-11 12:38:24,061: INFO: common]: created directory at: artifacts\n",
      "[2023-02-11 12:38:24,062: INFO: 4239026115]: artifacts directory created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_training_config = config.get_model_training_config()\n",
    "    model_trainer = ModelTrainer(config=model_training_config)\n",
    "    model_trainer.train_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26307cdd8260bd868184f67f182c2f8c81ec19bca50f3ee5e5c1717d66317ad9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
